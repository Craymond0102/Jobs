{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LAB 3: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "#The data is a csv file of houses on the market. Variables include selling price,\n",
    "#list price, living, rooms, beds, bath, age of house, land, and taxes\n",
    "\n",
    "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/homes.csv\"\n",
    "names = ['Sell', 'List', 'Living', 'Rooms', 'Beds', 'Baths', 'Age', 'Acres', 'Taxes']\n",
    "myData = pd.read_csv(url, header= 0, names=names, dtype = np.float64)\n",
    "myData = myData.drop(labels = 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData.head()\n",
    "#x = myData.data[:, :2]\n",
    "#y = myData.target\n",
    "myData.shape\n",
    "#print myData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The features are everything except Sell\n",
    "#The sell column is our target variable\n",
    "X = myData.drop([\"Sell\"], axis = 1)\n",
    "y = myData.Sell\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 8), (15, 8), (34,), (15,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can split the data using an sklearn function which does everything for us\n",
    "test_percent = 0.3 # why am I using .3 here?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percent)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 8), (5,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_percent = .33\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=test_percent)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 179.54423193  153.17292218  272.6551167   157.15890523  181.53408327\n",
      "   87.85562885  187.2510362   179.00591413  133.15321041  144.91593192]\n",
      "[  9.76971685e-01  -4.03053653e-01   3.55676982e-01   4.30070787e+00\n",
      "  -7.96427841e-01  -5.11386995e-02   5.21851387e-01  -2.32544284e-03]\n",
      "Root mean squared error: 4.92180636133\n",
      "R2: 0.987924439641\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "data_prediction_validate = regr.predict(X_validation)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_validation, data_prediction_validate))\n",
    "r2 = regr.score(X_validation, y_validation)\n",
    "print data_prediction_validate\n",
    "print regr.coef_\n",
    "print(\"Root mean squared error: \" + str(rmse))\n",
    "print(\"R2: \" + str(r2))\n",
    "\n",
    "#print('Coefficients: ', regr.coef_)\n",
    "#print(\"Mean squared error: %.2f\"\n",
    "     # % mean_squared_error(y_test, data_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     List  Living  Rooms  Beds  Baths   Age  Acres   Taxes\n",
      "45  135.0    10.0    6.0   3.0    1.0  15.0   1.00  2438.0\n",
      "46  145.0    21.0    7.0   4.0    2.0  10.0   1.20  3529.0\n",
      "19  153.0    19.0    8.0   4.0    2.0  24.0   0.34  3561.0\n",
      "13  116.0    20.0    8.0   4.0    1.0  13.0   0.22  2818.0\n",
      "25  165.0    20.0    8.0   4.0    2.0   7.0   0.30  3785.0\n",
      "45    129.0\n",
      "46    143.0\n",
      "19    151.0\n",
      "13    106.0\n",
      "25    157.0\n",
      "Name: Sell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print X_test\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 133.54533733  140.56442663  148.30283624  114.77596565  159.95102744]\n",
      "[  9.76971685e-01  -4.03053653e-01   3.55676982e-01   4.30070787e+00\n",
      "  -7.96427841e-01  -5.11386995e-02   5.21851387e-01  -2.32544284e-03]\n",
      "Root mean squared error: 4.89066329826\n",
      "R2: 0.927816913638\n"
     ]
    }
   ],
   "source": [
    "data_prediction_test = regr.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, data_prediction_test))\n",
    "r2 = regr.score(X_test, y_test)\n",
    "print data_prediction_test\n",
    "print regr.coef_\n",
    "print(\"Root mean squared error: \" + str(rmse))\n",
    "print(\"R2: \" + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4a) the results show that our predicted values are very similar to the actual values, and we get a very nice R squared\n",
    "#We were able to calculare the coefficients for each feature and accurately predict the output.\n",
    "#Its hard to see if the data has a linear relationship because there are 8 features which would produce a picture \n",
    "#Many dimensions\n",
    "#b) The coefficients all look very reasonable, mostly values between 0 and 5\n",
    "#5) THe sklearn function we would use would be .Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6) On this part I did not work with anyone. I completed using your content and online resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3), (10,), (5, 3), (5,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Load in the data\n",
    "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/homes.csv\"\n",
    "names = ['Sell', 'List', 'Living', 'Rooms', 'Beds', 'Baths', 'Age', 'Acres', 'Taxes']\n",
    "data = pd.read_csv(url, header= 0, names=names, dtype = np.float64)\n",
    "data = data.drop(labels = 0, axis=0)\n",
    "\n",
    "#List and Taxes have a linear relationship, so I chose to use these variables\n",
    "#The target variable is Sell\n",
    "Beds = data['Beds'].values\n",
    "Living = data['Living'].values\n",
    "Rooms = data['Rooms'].values\n",
    "List = data['List'].values\n",
    "Taxes = data['Taxes'].values\n",
    "Baths = data['Baths'].values\n",
    "Age = data['Age'].values\n",
    "Acres = data['Acres'].values\n",
    "Sell = data['Sell'].values\n",
    "\n",
    "#Need to genereate our X values and Y values\n",
    "\n",
    "#The amount of items in list \n",
    "N =  len(List)\n",
    "\n",
    "#Array of 1's\n",
    "x0 = np.ones(N)\n",
    "\n",
    "#Array(matrix) for our x values\n",
    "X = np.array([x0, List, Taxes]).T#Living, Rooms, Beds, Baths, Age, Acres, Taxes]).T\n",
    "\n",
    "#These are the starting coefficients for each column. Started with 0's. B = theta\n",
    "B = np.array([0, 0, 0])#, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "#this is our target variable\n",
    "Y = np.array(Sell)\n",
    "\n",
    "#starting learning step\n",
    "alpha = .01\n",
    "\n",
    "\n",
    "#splitting data into train, validate, test sets\n",
    "# we can split the data using an sklearn function which does everything for us\n",
    "test_percent = 0.3 # why am I using .3 here?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_percent)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "\n",
    "#further\n",
    "test_percent = .33\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=test_percent)\n",
    "X_validation.shape, y_validation.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17985.5147059\n"
     ]
    }
   ],
   "source": [
    "#Defining cost function J(theta)\n",
    "\n",
    "def cost_function(X, Y, B):\n",
    "    m = len(Y)\n",
    "    J = np.sum((X.dot(B) - Y)**2)/(2*m)\n",
    "    return J\n",
    "\n",
    "initial_cost = cost_function(X_train, y_train, B)\n",
    "print(initial_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for predicted y (h):[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Values for predicted y (h):[-12216244.91014706  -5514633.62191176 -10615516.42485294\n",
      " -17647574.06367647 -12816414.64838235 -15870477.40132353\n",
      " -13595014.05073529  -7985317.88897059 -19666414.78661764\n",
      " -11827234.54838235 -12862061.51014706 -46503393.28661764\n",
      " -13909254.78955882 -11653004.43779412 -14431422.13661765\n",
      " -12766017.40132353 -12708929.23661765 -15180524.59485294\n",
      " -11889059.17485294 -13279615.95426471 -13922594.8542647   -9301063.27485294\n",
      " -21747489.12779412 -15056875.34191176 -12216251.87191176\n",
      " -14936472.78073529 -15377793.07485294 -14360668.45661765\n",
      "  -5621554.27838235 -14950363.67720588 -12822117.89544118\n",
      " -11665554.36602941 -14610239.90720588 -10743146.81191176]\n",
      "Values for predicted y (h):[ -1.01685817e+12  -4.59011512e+11  -8.83597515e+11  -1.46891569e+12\n",
      "  -1.06680170e+12  -1.32101405e+12  -1.13159914e+12  -6.64609369e+11\n",
      "  -1.63698209e+12  -9.84478196e+11  -1.07061076e+12  -3.87078041e+12\n",
      "  -1.15777041e+12  -9.69954376e+11  -1.20123473e+12  -1.06259025e+12\n",
      "  -1.05786593e+12  -1.26359301e+12  -9.89622327e+11  -1.10535289e+12\n",
      "  -1.15884837e+12  -7.74183456e+11  -1.81018860e+12  -1.25330475e+12\n",
      "  -1.01684946e+12  -1.24326958e+12  -1.28000629e+12  -1.19533200e+12\n",
      "  -4.67892384e+11  -1.24441986e+12  -1.06728110e+12  -9.71005566e+11\n",
      "  -1.21611073e+12  -8.94235283e+11]\n",
      "Values for predicted y (h):[ -8.46390396e+16  -3.82062067e+16  -7.35469775e+16  -1.22266425e+17\n",
      "  -8.87961313e+16  -1.09955709e+17  -9.41896002e+16  -5.53193158e+16\n",
      "  -1.36255572e+17  -8.19438655e+16  -8.91131813e+16  -3.22187642e+17\n",
      "  -9.63679873e+16  -8.07349630e+16  -9.99857769e+16  -8.84455873e+16\n",
      "  -8.80523546e+16  -1.05176221e+17  -8.23720415e+16  -9.20049717e+16\n",
      "  -9.64577126e+16  -6.44398069e+16  -1.50672560e+17  -1.04319868e+17\n",
      "  -8.46383149e+16  -1.03484582e+17  -1.06542394e+17  -9.94944582e+16\n",
      "  -3.89454134e+16  -1.03580327e+17  -8.88360343e+16  -8.08224597e+16\n",
      "  -1.01223993e+17  -7.44324211e+16]\n",
      "Values for predicted y (h):[ -7.04500119e+21  -3.18012554e+21  -6.12174413e+21  -1.01769481e+22\n",
      "  -7.39102019e+21  -9.15225529e+21  -7.83995008e+21  -4.60454947e+21\n",
      "  -1.13413464e+22  -6.82066612e+21  -7.41741011e+21  -2.68175576e+22\n",
      "  -8.02126995e+21  -6.72004211e+21  -8.32239969e+21  -7.36184237e+21\n",
      "  -7.32911132e+21  -8.75443061e+21  -6.85630571e+21  -7.65811070e+21\n",
      "  -8.02873831e+21  -5.36370117e+21  -1.25413565e+22  -8.68315143e+21\n",
      "  -7.04494087e+21  -8.61362567e+21  -8.86814516e+21  -8.28150437e+21\n",
      "  -3.24165402e+21  -8.62159506e+21  -7.39434155e+21  -6.72732497e+21\n",
      "  -8.42546365e+21  -6.19544477e+21]\n",
      "Values for predicted y (h):[ -5.86396561e+26  -2.64700407e+26  -5.09548488e+26  -8.47086775e+26\n",
      "  -6.15197742e+26  -7.61795617e+26  -6.52564797e+26  -3.83263523e+26\n",
      "  -9.44006446e+26  -5.67723844e+26  -6.17394329e+26  -2.23218182e+27\n",
      "  -6.67657107e+26  -5.59348320e+26  -6.92721893e+26  -6.12769101e+26\n",
      "  -6.10044705e+26  -7.28682347e+26  -5.70690335e+26  -6.37429244e+26\n",
      "  -6.68278742e+26  -4.46452149e+26  -1.04389029e+27  -7.22749365e+26\n",
      "  -5.86391540e+26  -7.16962331e+26  -7.38147473e+26  -6.89317936e+26\n",
      "  -2.69821782e+26  -7.17625669e+26  -6.15474198e+26  -5.59954516e+26\n",
      "  -7.01300508e+26  -5.15683022e+26]\n",
      "Values for predicted y (h):[ -4.88092078e+31  -2.20325596e+31  -4.24126942e+31  -7.05079756e+31\n",
      "  -5.12064981e+31  -6.34086947e+31  -5.43167761e+31  -3.19012596e+31\n",
      "  -7.85751654e+31  -4.72549686e+31  -5.13893329e+31  -1.85797519e+32\n",
      "  -5.55729973e+31  -4.65578249e+31  -5.76592856e+31  -5.10043482e+31\n",
      "  -5.07775808e+31  -6.06524841e+31  -4.75018869e+31  -5.30569558e+31\n",
      "  -5.56247396e+31  -3.71608177e+31  -8.68890803e+31  -6.01586474e+31\n",
      "  -4.88087899e+31  -5.96769587e+31  -6.14403217e+31  -5.73759544e+31\n",
      "  -2.24588415e+31  -5.97321722e+31  -5.12295092e+31  -4.66082820e+31\n",
      "  -5.83733338e+31  -4.29233073e+31]\n",
      "Values for predicted y (h):[ -4.06267520e+36  -1.83389851e+36  -3.53025605e+36  -5.86879027e+36\n",
      "  -4.26221566e+36  -5.27787569e+36  -4.52110225e+36  -2.65532800e+36\n",
      "  -6.54026955e+36  -3.93330680e+36  -4.27743406e+36  -1.54650118e+37\n",
      "  -4.62566487e+36  -3.87527946e+36  -4.79931882e+36  -4.24538954e+36\n",
      "  -4.22651437e+36  -5.04846020e+36  -3.95385925e+36  -4.41624005e+36\n",
      "  -4.62997168e+36  -3.09311172e+36  -7.23228520e+36  -5.00735528e+36\n",
      "  -4.06264041e+36  -4.96726153e+36  -5.11403652e+36  -4.77573551e+36\n",
      "  -1.86938044e+36  -4.97185727e+36  -4.26413101e+36  -3.87947930e+36\n",
      "  -4.85875322e+36  -3.57275735e+36]\n",
      "Values for predicted y (h):[ -3.38160165e+41  -1.52646075e+41  -2.93843812e+41  -4.88493662e+41\n",
      "  -3.54769082e+41  -4.39308394e+41  -3.76317724e+41  -2.21018445e+41\n",
      "  -5.44384801e+41  -3.27392078e+41  -3.56035799e+41  -1.28724318e+42\n",
      "  -3.85021080e+41  -3.22562124e+41  -3.99475313e+41  -3.53368546e+41\n",
      "  -3.51797455e+41  -4.20212803e+41  -3.29102779e+41  -3.67589431e+41\n",
      "  -3.85379562e+41  -2.57457738e+41  -6.01985303e+41  -4.16791401e+41\n",
      "  -3.38157270e+41  -4.13454164e+41  -4.25671103e+41  -3.97512336e+41\n",
      "  -1.55599443e+41  -4.13836695e+41  -3.54928507e+41  -3.22911702e+41\n",
      "  -4.04422384e+41  -2.97381444e+41]\n",
      "Values for predicted y (h):[ -2.81470439e+46  -1.27056236e+46  -2.44583352e+46  -4.06601782e+46\n",
      "  -2.95295010e+46  -3.65662013e+46  -3.13231202e+46  -1.83966550e+46\n",
      "  -4.53123238e+46  -2.72507532e+46  -2.96349372e+46  -1.07144761e+47\n",
      "  -3.20475514e+46  -2.68487279e+46  -3.32506615e+46  -2.94129262e+46\n",
      "  -2.92821552e+46  -3.49767638e+46  -2.73931448e+46  -3.05966135e+46\n",
      "  -3.20773899e+46  -2.14297100e+46  -5.01067497e+46  -3.46919806e+46\n",
      "  -2.81468029e+46  -3.44142029e+46  -3.54310900e+46  -3.30872715e+46\n",
      "  -1.29514496e+46  -3.44460431e+46  -2.95427709e+46  -2.68778253e+46\n",
      "  -3.36624351e+46  -2.47527930e+46]\n",
      "Values for predicted y (h):[ -2.34284272e+51  -1.05756320e+51  -2.03580997e+51  -3.38438391e+51\n",
      "  -2.45791269e+51  -3.04361832e+51  -2.60720609e+51  -1.53126095e+51\n",
      "  -3.77160914e+51  -2.26823921e+51  -2.46668876e+51  -8.91828376e+51\n",
      "  -2.66750472e+51  -2.23477631e+51  -2.76764659e+51  -2.44820949e+51\n",
      "  -2.43732465e+51  -2.91132016e+51  -2.28009130e+51  -2.54673469e+51\n",
      "  -2.66998835e+51  -1.78371982e+51  -4.17067718e+51  -2.88761599e+51\n",
      "  -2.34282266e+51  -2.86449493e+51  -2.94913638e+51  -2.75404669e+51\n",
      "  -1.07802473e+51  -2.86714518e+51  -2.45901722e+51  -2.23719825e+51\n",
      "  -2.80192091e+51  -2.06031941e+51]\n",
      "Values for predicted y (h):[ -1.95008472e+56  -8.80271563e+55  -1.69452344e+56  -2.81702023e+56\n",
      "  -2.04586417e+56  -2.53338114e+56  -2.17012977e+56  -1.27455785e+56\n",
      "  -3.13933038e+56  -1.88798786e+56  -2.05316901e+56  -7.42320801e+56\n",
      "  -2.22031984e+56  -1.86013473e+56  -2.30367377e+56  -2.03778763e+56\n",
      "  -2.02872754e+56  -2.42326167e+56  -1.89785305e+56  -2.11979590e+56\n",
      "  -2.22238711e+56  -1.48469410e+56  -3.47149800e+56  -2.40353130e+56\n",
      "  -1.95006802e+56  -2.38428629e+56  -2.45473831e+56  -2.29235378e+56\n",
      "  -8.97302896e+55  -2.38649225e+56  -2.04678354e+56  -1.86215066e+56\n",
      "  -2.33220229e+56  -1.71492408e+56]\n",
      "Values for predicted y (h):[ -1.62316931e+61  -7.32701392e+60  -1.41045075e+61  -2.34477033e+61\n",
      "  -1.70289214e+61  -2.10868096e+61  -1.80632565e+61  -1.06088888e+61\n",
      "  -2.61304788e+61  -1.57148248e+61  -1.70897238e+61  -6.17876922e+61\n",
      "  -1.84810178e+61  -1.54829869e+61  -1.91748211e+61  -1.69616956e+61\n",
      "  -1.68862832e+61  -2.01702210e+61  -1.57969384e+61  -1.76442983e+61\n",
      "  -1.84982249e+61  -1.23579754e+61  -2.88953037e+61  -2.00059936e+61\n",
      "  -1.62315541e+61  -1.98458062e+61  -2.04322195e+61  -1.90805982e+61\n",
      "  -7.46877564e+60  -1.98641677e+61  -1.70365738e+61  -1.54997666e+61\n",
      "  -1.94122806e+61  -1.42743138e+61]\n",
      "Values for predicted y (h):[ -1.35105854e+66  -6.09870126e+65  -1.17400047e+66  -1.95168917e+66\n",
      "  -1.41741650e+66  -1.75517822e+66  -1.50351025e+66  -8.83039721e+65\n",
      "  -2.17499224e+66  -1.30803657e+66  -1.42247744e+66  -5.14295019e+66\n",
      "  -1.53828296e+66  -1.28873935e+66  -1.59603226e+66  -1.41182091e+66\n",
      "  -1.40554390e+66  -1.67888520e+66  -1.31487137e+66  -1.46863791e+66\n",
      "  -1.53971520e+66  -1.02862641e+66  -2.40512475e+66  -1.66521560e+66\n",
      "  -1.35104697e+66  -1.65188226e+66  -1.70069286e+66  -1.58818954e+66\n",
      "  -6.21669781e+65  -1.65341060e+66  -1.41805346e+66  -1.29013603e+66\n",
      "  -1.61579740e+66  -1.18813444e+66]\n",
      "Values for predicted y (h):[ -1.12456486e+71  -5.07630496e+70  -9.77189098e+70  -1.62450479e+71\n",
      "  -1.17979847e+71  -1.46093726e+71  -1.25145932e+71  -7.35005490e+70\n",
      "  -1.81037296e+71  -1.08875517e+71  -1.18401098e+71  -4.28077757e+71\n",
      "  -1.28040267e+71  -1.07269297e+71  -1.32847079e+71  -1.17514093e+71\n",
      "  -1.16991621e+71  -1.39743412e+71  -1.09444417e+71  -1.22243304e+71\n",
      "  -1.28159482e+71  -8.56185786e+70  -2.00192569e+71  -1.38605612e+71\n",
      "  -1.12455524e+71  -1.37495801e+71  -1.41558592e+71  -1.32194283e+71\n",
      "  -5.17452037e+70  -1.37623013e+71  -1.18032864e+71  -1.07385550e+71\n",
      "  -1.34492247e+71  -9.88953631e+70]\n",
      "[ -6.50162049e+68  -1.41755787e+71  -2.91525687e+72]\n",
      "[120779943740876.77, 8.3678812960292908e+23, 5.7974391467727525e+33, 4.0165843027053767e+43, 2.7827716776846087e+53, 1.9279610799922102e+63, 1.3357308311609197e+73, 9.2542161344929761e+82, 6.4115100337601432e+92, 4.4420251608116536e+102, 3.0775257974152871e+112, 2.1321727569922245e+122, 1.477212853740492e+132, 1.0234432496616332e+142, 7.0906239586646108e+151]\n"
     ]
    }
   ],
   "source": [
    "#now we need to define out Gradient Descent function\n",
    "\n",
    "def gradient_descent(X, Y, B, alpha, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    N = float(len(Y))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "       # print(\"Value for B:\" + str(B))\n",
    "        #print(\"value for X: \" + str(X))\n",
    "        #print(\"value for Y: \" + str(Y))\n",
    "\n",
    "\n",
    "        #Predicted value\n",
    "        h = X.dot(B)\n",
    "        print(\"Values for predicted y (h):\" + str(h))\n",
    "       # print(\"value for Y: \" + str(Y))\n",
    "\n",
    "        #get predicted minus new\n",
    "        difference = h - Y\n",
    "       # print(\"Value for  pred_y-y :\" + str(sumy_xtheta))\n",
    "        #print(\"value for X: \" + str(X))\n",
    "        \n",
    "        #gradient calculation\n",
    "        gradient = (difference.T.dot(X)) / -(2*N)\n",
    "        F = X.T.dot(difference)\n",
    "       # print\n",
    "       # print\n",
    "       # print(\"The value of X dot pred_(F): \" + str(F))\n",
    "       # print(\"The value of N :\" + str(N))\n",
    "       # print(\"The gradient is: \" + str(gradient))\n",
    "        \n",
    "        #update gradient\n",
    "        B = B - (alpha * gradient)\n",
    "        \n",
    "       # print(\"B AGAIN (alpha is .7): \" +str(B))\n",
    "        \n",
    "        #New Cost Value\n",
    "        cost = cost_function(X, Y, B)\n",
    "        cost_history[iteration] = cost\n",
    "    return B, cost_history\n",
    "\n",
    "newB, cost_history = gradient_descent(X_train, y_train, B, alpha, 15)\n",
    "\n",
    "print(newB)\n",
    "print(cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
